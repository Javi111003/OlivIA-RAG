from datetime import datetime
import json
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from  agents.dto_s.agent_formated_responses import MathExpertResponse
from  agents.dto_s.agent_state import EstadoConversacion
from  generator.llm_provider import MistralLLMProvider
from agents.specialised_agents.knowledge_analyzer import KnowledgeAnalyzerAgent
import asyncio
import logging
from typing import Dict

logger = logging.getLogger(__name__)

class MathExpert():
    
    def __init__(self, llm: MistralLLMProvider):
        """Factory function para crear agente matem√°tico avanzado"""
        self.llm = llm
        self.llm_structured = llm.with_structured_output(MathExpertResponse)
        self.parser = JsonOutputParser(pydantic_object=MathExpertResponse)

        self.prompt = ChatPromptTemplate.from_template(
             """
            Eres un experto en matem√°ticas con enfoque pedag√≥gico personalizado.
            
            PERFIL DEL ESTUDIANTE:
            - Nivel de comprensi√≥n general: {nivel_comprension}
            - Puntuaci√≥n general: {knowledge_areas[overall_score]}/10
            
            √ÅREAS DE FORTALEZA (Score ‚â• 7):
            {knowledge_areas[strong_areas]}
            
            √ÅREAS DE DEBILIDAD (Score ‚â§ 4):
            {knowledge_areas[weak_areas]}
            
            CAMPOS LEGACY (para compatibilidad):
            - Temas dominados: {temas_dominados}
            - √Åreas de dificultad: {areas_dificultad}
            - Errores hist√≥ricos: {historial_errores}
            - Preferencias: {preferencias}
            
            CONTEXTO DE LA CONSULTA:
            - Consulta original: {consulta_inicial}
            - Contexto conversacional: {contexto_conversacional}
            - Contexto recuperado: {contexto_recuperado}
            - Estado BDI: {bdi_context}
            - Historial reciente: {chat_history}
            
            AN√ÅLISIS DE REFERENCIAS TEMPORALES:
            Revisa cuidadosamente si la consulta incluye referencias como:
            - "anteriormente", "antes", "previo", "mencionamos", "hablamos de"
            - "el teorema que", "la f√≥rmula que", "el concepto que"
            - "contin√∫a", "sigue", "siguiente", "m√°s sobre"
            
            Si la consulta contiene referencias temporales:
            1. PRIORIDAD M√ÅXIMA: Busca en el historial conversacional (chat_history)
            2. Identifica qu√© teorema/concepto/ejercicio/examen se mencion√≥ espec√≠ficamente
            3. NO uses el contexto RAG recuperado cuando exista una referencia temporal a algo pues el usuario no sabe del contexto recuperado
            4. Si no encuentras la referencia en el historial, indica que no hay contexto previo
            
            INSTRUCCIONES PEDAG√ìGICAS AVANZADAS:
            1. **Personalizaci√≥n por √°reas**: Adapta la explicaci√≥n considerando las puntuaciones espec√≠ficas por √°rea
            2. **Aprovecha fortalezas**: Conecta conceptos nuevos con √°reas donde tiene buena puntuaci√≥n
            3. **Refuerza debilidades**: Si la consulta toca √°reas d√©biles, proporciona apoyo extra
            4. **Detecta progreso**: Identifica si la consulta muestra mejora en √°reas previamente d√©biles
            5. **Contextualizaci√≥n**: Usa el contexto conversacional para referencias espec√≠ficas
            
            INSTRUCCIONES IMPORTANTES:
            1. **PRIORIDAD**: Si la consulta referencia algo previo ("ejercicio 1", "t√∫ examen","el teorema") o no aparece en la consulta el sujeto o cosa de la cual se habla, usa contexto conversacional √∫nicamente.
            Si no hay referencia previa, usa el contexto general de conocimiento matem√°tico.
            2. **AREAS ESPEC√çFICAS**: Menciona qu√© √°rea de conocimiento est√°s trabajando
            3. **PROGRESO**: Si detectas mejora, recon√≥celo expl√≠citamente
            4. **CONEXIONES**: Conecta con √°reas fuertes para facilitar comprensi√≥n
            
            EJEMPLOS DE RESPUESTA:
            - "Bas√°ndome en el examen que cre√© anteriormente..."
            - "Refiri√©ndome al ejercicio 1 del examen que gener√©..."
            - "En relaci√≥n al teorema que discutimos..."
            - "Seg√∫n el contexto de nuestra conversaci√≥n previa..."
            - "Como no encuentro referencia previa espec√≠fica, te ayudo con informaci√≥n general..."
                        
            FORMATO DE RESPUESTA:
            - explanation: Explicaci√≥n detallada y personalizada
            - formulas: Lista de f√≥rmulas relevantes (LaTeX si aplica)
            - difficulty_level: Eval√∫a la dificultad para este estudiante espec√≠fico
            - related_concepts: Conceptos que conectan con conocimiento previo
            
            IMPORTANTE: Responde √öNICAMENTE con JSON v√°lido, sin markdown, sin comillas adicionales.

            {format_instructions}
            """
        )

    async def math_expert_chain(self, estado: EstadoConversacion) -> EstadoConversacion:
        """Cadena principal del experto matem√°tico"""
        print(f"Math Expert procesando: {estado.consulta_inicial}")
        try:
            # Preparar contexto personalizado
            student_context = estado.estado_estudiante.model_dump()
            bdi_context = estado.bdi_state.model_dump() if estado.bdi_state else {}
            
            knowledge_context = self._extract_knowledge_context(estado.estado_estudiante.math_knowledge)
            contexto_conversacional = self._extraer_contexto_conversacional(estado)

            prompt_data = {
                "nivel_comprension": student_context.get("nivel_comprension"),
                "temas_dominados": student_context.get("temas_dominados", []),
                "areas_dificultad": student_context.get("areas_dificultad", []),
                "historial_errores": student_context.get("historial_errores", []),
                "preferencias": student_context.get("preferencias_aprendizaje", {}),
                "knowledge_areas": knowledge_context,
                "consulta_inicial": estado.consulta_inicial,
                "contexto_conversacional": contexto_conversacional,
                "contexto_recuperado": estado.contexto_recuperado,
                "bdi_context": bdi_context,
                "chat_history": estado.chat_history[-5:],  # √öltimas 5 interacciones
                "format_instructions": self.parser.get_format_instructions()
            }
            
            respuesta_raw = None
            # Ejecutar con fallback
            try:
                formatted_prompt = self.prompt.format(**prompt_data)
                respuesta_raw = await self.llm_structured.ainvoke(formatted_prompt)
                logger.info(f"‚úÖ Structured output exitoso: {type(respuesta_raw)}")
                print(repr(respuesta_raw))  # Log completo de la respuesta
                print(f"Respuesta del experto matem√°tico: {respuesta_raw.explanation[:100]}...")  # Log parcial
            except Exception as structured_error:
                logger.warning(f"‚ö†Ô∏è Math expert structured output fall√≥: {structured_error}")
                try:
                    formatted_prompt = self.prompt.format(**prompt_data)
                    respuesta_raw = await self.llm.ainvoke(formatted_prompt)
                    logger.info(f"üìù Raw response obtenida: {type(respuesta_raw)}")
                    
                    # Intentar parsing manual
                    if isinstance(respuesta_raw, str):
                        try:
                            respuesta_raw = json.loads(str(respuesta_raw))
                            logger.info("‚úÖ JSON parsing manual exitoso")
                        except json.JSONDecodeError:
                            logger.warning("‚ö†Ô∏è No se pudo parsear JSON manualmente")
                    
                except Exception as raw_error:
                    logger.error(f"‚ùå Raw response tambi√©n fall√≥: {raw_error}")
                    respuesta_raw = {}
            
            respuesta = self.ensure_math_expert_response(respuesta_raw, estado.consulta_inicial)
            
            logger.info(f"üéØ Respuesta final normalizada: {type(respuesta)}")
            logger.info(f"üìù Explicaci√≥n: {respuesta.explanation[:100]}...")
            
            estado.respuesta_math_expert = respuesta.explanation
            estado.estado_actual = "math_expert_completado"
            
            estado.chat_history.append({
                "role": "math_expert",
                "content": respuesta.explanation,
                "metadata": {
                    "formulas": respuesta.formulas,
                    "difficulty_assessed": respuesta.difficulty_level,
                    "related_concepts": respuesta.related_concepts,
                    "timestamp": datetime.now().isoformat(),
                    "personalization_applied": True
                }
            })
            
            # Actualizar perfil del estudiante basado en la interacci√≥n
            #self.actualizar_perfil_estudiante(estado, respuesta)
            
            print("Actualizando perfil del estudiante...")
            await self._analyze_and_update_knowledge(estado, respuesta)
            
            logger.info(f"Math expert complet√≥ respuesta (dificultad: {respuesta.difficulty_level})")
            return estado
            
        except Exception as e:
            logger.error(f"Error en math expert: {e}")
            estado.respuesta_math_expert = "Lo siento, ocurri√≥ un error al procesar tu consulta matem√°tica."
            estado.estado_actual = "math_expert_error"
            return estado
    

    def actualizar_perfil_estudiante(self, estado: EstadoConversacion, respuesta: MathExpertResponse) -> None:
        """Actualiza el perfil del estudiante basado en la interacci√≥n"""
        # Actualizar temas dominados si la dificultad es apropiada
        if respuesta.difficulty_level == "b√°sico":
            for concepto in respuesta.related_concepts:
                if concepto not in estado.estado_estudiante.temas_dominados:
                    estado.estado_estudiante.temas_dominados.append(concepto)
        
        # Ajustar nivel de comprensi√≥n si es necesario
        if respuesta.difficulty_level == "avanzado" and estado.estado_estudiante.nivel_comprension == "principiante":
            estado.estado_estudiante.nivel_comprension = "intermedio"
    
    def ensure_math_expert_response(self, respuesta, consulta: str) -> MathExpertResponse:
        """Convierte cualquier formato de respuesta a MathExpertResponse"""
        try:
            # Si ya es MathExpertResponse, devolverlo tal cual
            if isinstance(respuesta, MathExpertResponse):
                return respuesta
            
            # Si es dict, convertir a MathExpertResponse
            if isinstance(respuesta, dict):
                return MathExpertResponse(
                    explanation=respuesta.get('explanation', f'Explicaci√≥n sobre: {consulta}'),
                    formulas=respuesta.get('formulas', []),
                    difficulty_level=respuesta.get('difficulty_level', 'b√°sico'),
                    related_concepts=respuesta.get('related_concepts', [])
                )
            
            # Si es string (JSON), parsearlo primero
            if isinstance(respuesta, str):
                try:
                    json_data = json.loads(respuesta)
                    return MathExpertResponse(
                        explanation=json_data.get('explanation', f'Explicaci√≥n sobre: {consulta}'),
                        formulas=json_data.get('formulas', []),
                        difficulty_level=json_data.get('difficulty_level', 'b√°sico'),
                        related_concepts=json_data.get('related_concepts', [])
                    )
                except json.JSONDecodeError:
                    pass
            
            # Fallback si no se puede convertir
            logger.warning(f"No se pudo convertir respuesta de tipo {type(respuesta)}, usando fallback")
            return MathExpertResponse(
                explanation=f"Respuesta sobre: {consulta}. {str(respuesta)[:200]}",
                formulas=[],
                difficulty_level='b√°sico',
                related_concepts=[]
            )
            
        except Exception as e:
            logger.error(f"Error convirtiendo respuesta: {e}")
            return MathExpertResponse(
                explanation=f"Error procesando consulta sobre: {consulta}",
                formulas=[],
                difficulty_level='b√°sico',
                related_concepts=[]
            )
            
    def _extraer_contexto_conversacional(self, estado: EstadoConversacion) -> str:
        """Extrae contexto relevante de la conversaci√≥n previa"""
        contexto_partes = []
        
        for mensaje in estado.chat_history[-5:]:
            if mensaje.get("role") == "exam_creator":
                contexto_partes.append(f"EXAMEN CREADO PREVIAMENTE:\n{mensaje['content']}\n")
            elif mensaje.get("role") == "math_expert":
                contexto_partes.append(f"EXPLICACI√ìN PREVIA:\n{mensaje['content'][:300]}...\n")
            elif mensaje.get("role") == "user":
                contexto_partes.append(f"CONSULTA DEL USUARIO:\n{mensaje['content'][:300]}...\n")
        
        if not contexto_partes:
            return "No hay contexto conversacional previo."
        
        return "\n".join(contexto_partes)
    
    def _extract_knowledge_context(self, math_knowledge) -> Dict:
        """Extrae contexto relevante de las √°reas de conocimiento"""
        all_areas = math_knowledge.get_all_areas()
        
        # √Åreas fuertes (score >= 7)
        strong_areas = [
            {"name": area.name, "score": area.score, "topics": area.topics_mastered}
            for area in all_areas.values() if area.score >= 7
        ]
        
        # √Åreas d√©biles (score <= 4)
        weak_areas = [
            {"name": area.name, "score": area.score, "struggles": area.topics_struggling}
            for area in all_areas.values() if area.score <= 4
        ]
        
        # Puntuaci√≥n general
        overall_score = math_knowledge.get_overall_score()
        
        return {
            "overall_score": round(overall_score, 1),
            "strong_areas": strong_areas,
            "weak_areas": weak_areas,
            "relevant_areas": [area.name for area in all_areas.values()]
        }
    
    async def _analyze_and_update_knowledge(self, estado: EstadoConversacion, respuesta: MathExpertResponse):
        """Analiza la interacci√≥n y actualiza el conocimiento del estudiante"""
        try:
            # Crear analizador (lazy import para evitar ciclos)            
            analyzer = KnowledgeAnalyzerAgent(self.llm)
            
            analysis = await analyzer.analyze_knowledge_from_interaction(estado)
            print(f"üîçüîçüîçAn√°lisis de conocimiento: {analysis}")
            if analysis:
                estado = analyzer.update_student_knowledge(estado, analysis)
                logger.info("‚úÖ Conocimiento del estudiante actualizado autom√°ticamente")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error en an√°lisis autom√°tico de conocimiento: {e}")