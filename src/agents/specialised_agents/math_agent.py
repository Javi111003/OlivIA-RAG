from datetime import datetime
import json
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from  agents.dto_s.agent_formated_responses import MathExpertResponse
from  agents.dto_s.agent_state import EstadoConversacion
from  generator.llm_provider import MistralLLMProvider
import asyncio
import logging

logger = logging.getLogger(__name__)

class MathExpert():
    
    def __init__(self, llm: MistralLLMProvider):
        """Factory function para crear agente matem√°tico avanzado"""
        self.llm = llm
        self.llm_structured = llm.with_structured_output(MathExpertResponse)
        self.parser = JsonOutputParser(pydantic_object=MathExpertResponse)

        self.prompt = ChatPromptTemplate.from_template(
            """
            Eres un experto en matem√°ticas con enfoque pedag√≥gico personalizado.
            
            PERFIL DEL ESTUDIANTE:
            - Nivel de comprensi√≥n: {nivel_comprension}
            - Temas ya dominados: {temas_dominados}
            - √Åreas de dificultad conocidas: {areas_dificultad}
            - Errores hist√≥ricos: {historial_errores}
            - Preferencias de aprendizaje: {preferencias}
            
            CONTEXTO DE LA CONSULTA:
            - Consulta original: {consulta_inicial}
            - Contexto recuperado: {contexto_recuperado}
            - Estado BDI actual: {bdi_context}
            - Historial de conversaci√≥n: {chat_history}
            
            INSTRUCCIONES PEDAG√ìGICAS:
            1. Adapta la explicaci√≥n al nivel del estudiante
            2. Conecta con conocimientos previos (temas dominados)
            3. Anticipa confusiones bas√°ndote en errores hist√≥ricos
            4. Usa el estilo de aprendizaje preferido
            5. Proporciona f√≥rmulas relevantes y conceptos relacionados
            6. Incluye verificaciones de comprensi√≥n si es apropiado
            
            INSTRUCCIONES IMPORTANTES:
            1. **PRIORIDAD**: Si la consulta hace referencia a algo mencionado en la conversaci√≥n previa (como "ejercicio 1", "pregunta 1", "tu examen"), usa √öNICAMENTE el contexto conversacional, NO el contexto recuperado.
            
            2. Si la consulta menciona "ejercicio", "pregunta", "problema" + n√∫mero, busca espec√≠ficamente esa referencia en el contexto conversacional.
            
            3. Si no encuentras la referencia espec√≠fica en la conversaci√≥n previa, entonces puedes usar el contexto recuperado.
            
            4. Siempre menciona de d√≥nde viene la informaci√≥n que est√°s usando.
            
            EJEMPLOS DE RESPUESTA:
            - "Bas√°ndome en el examen que cre√© anteriormente..."
            - "Refiri√©ndome al ejercicio 1 del examen que gener√©..."
            - "Como no encuentro referencia previa espec√≠fica, te ayudo con informaci√≥n general..."
            
            
            FORMATO DE RESPUESTA:
            - explanation: Explicaci√≥n detallada y personalizada
            - formulas: Lista de f√≥rmulas relevantes (LaTeX si aplica)
            - difficulty_level: Eval√∫a la dificultad para este estudiante espec√≠fico
            - related_concepts: Conceptos que conectan con conocimiento previo
            
            IMPORTANTE: Responde √öNICAMENTE con JSON v√°lido, sin markdown, sin comillas adicionales.

            {format_instructions}
            """
        )

    async def math_expert_chain(self, estado: EstadoConversacion) -> EstadoConversacion:
        """Cadena principal del experto matem√°tico"""
        print(f"Math Expert procesando: {estado.consulta_inicial}")
        try:
            # Preparar contexto personalizado
            student_context = estado.estado_estudiante.model_dump()
            bdi_context = estado.bdi_state.model_dump() if estado.bdi_state else {}
            
            contexto_conversacional = self._extraer_contexto_conversacional(estado)

            prompt_data = {
                "nivel_comprension": student_context.get("nivel_comprension"),
                "temas_dominados": student_context.get("temas_dominados", []),
                "areas_dificultad": student_context.get("areas_dificultad", []),
                "historial_errores": student_context.get("historial_errores", []),
                "preferencias": student_context.get("preferencias_aprendizaje", {}),
                "consulta_inicial": estado.consulta_inicial,
                "contexto_conversacional": contexto_conversacional,
                "contexto_recuperado": estado.contexto_recuperado,
                "bdi_context": bdi_context,
                "chat_history": estado.chat_history[-5:],  # √öltimas 5 interacciones
                "format_instructions": self.parser.get_format_instructions()
            }
            
            respuesta_raw = None
            # Ejecutar con fallback
            try:
                formatted_prompt = self.prompt.format(**prompt_data)
                respuesta_raw = await self.llm_structured.ainvoke(formatted_prompt)
                logger.info(f"‚úÖ Structured output exitoso: {type(respuesta_raw)}")
                print(repr(respuesta_raw))  # Log completo de la respuesta
                print(f"Respuesta del experto matem√°tico: {respuesta_raw.explanation[:100]}...")  # Log parcial
            except Exception as structured_error:
                logger.warning(f"‚ö†Ô∏è Math expert structured output fall√≥: {structured_error}")
                try:
                    formatted_prompt = self.prompt.format(**prompt_data)
                    respuesta_raw = await self.llm.ainvoke(formatted_prompt)
                    logger.info(f"üìù Raw response obtenida: {type(respuesta_raw)}")
                    
                    # Intentar parsing manual
                    if isinstance(respuesta_raw, str):
                        try:
                            respuesta_raw = json.loads(str(respuesta_raw))
                            logger.info("‚úÖ JSON parsing manual exitoso")
                        except json.JSONDecodeError:
                            logger.warning("‚ö†Ô∏è No se pudo parsear JSON manualmente")
                    
                except Exception as raw_error:
                    logger.error(f"‚ùå Raw response tambi√©n fall√≥: {raw_error}")
                    respuesta_raw = {}
            
            respuesta = self.ensure_math_expert_response(respuesta_raw, estado.consulta_inicial)
            
            logger.info(f"üéØ Respuesta final normalizada: {type(respuesta)}")
            logger.info(f"üìù Explicaci√≥n: {respuesta.explanation[:100]}...")
            
            # Actualizar estado
            estado.respuesta_math_expert = respuesta.explanation
            estado.estado_actual = "math_expert_completado"
            
            # Actualizar historial con metadatos ricos
            estado.chat_history.append({
                "role": "math_expert",
                "content": respuesta.explanation,
                "metadata": {
                    "formulas": respuesta.formulas,
                    "difficulty_assessed": respuesta.difficulty_level,
                    "related_concepts": respuesta.related_concepts,
                    "timestamp": datetime.now().isoformat(),
                    "personalization_applied": True
                }
            })
            
            # Actualizar perfil del estudiante basado en la interacci√≥n
            self.actualizar_perfil_estudiante(estado, respuesta)
            
            logger.info(f"Math expert complet√≥ respuesta (dificultad: {respuesta.difficulty_level})")
            return estado
            
        except Exception as e:
            logger.error(f"Error en math expert: {e}")
            estado.respuesta_math_expert = "Lo siento, ocurri√≥ un error al procesar tu consulta matem√°tica."
            estado.estado_actual = "math_expert_error"
            return estado
    

    def actualizar_perfil_estudiante(self, estado: EstadoConversacion, respuesta: MathExpertResponse) -> None:
        """Actualiza el perfil del estudiante basado en la interacci√≥n"""
        # Actualizar temas dominados si la dificultad es apropiada
        if respuesta.difficulty_level == "b√°sico":
            for concepto in respuesta.related_concepts:
                if concepto not in estado.estado_estudiante.temas_dominados:
                    estado.estado_estudiante.temas_dominados.append(concepto)
        
        # Ajustar nivel de comprensi√≥n si es necesario
        if respuesta.difficulty_level == "avanzado" and estado.estado_estudiante.nivel_comprension == "principiante":
            estado.estado_estudiante.nivel_comprension = "intermedio"
    
    def ensure_math_expert_response(self, respuesta, consulta: str) -> MathExpertResponse:
        """Convierte cualquier formato de respuesta a MathExpertResponse"""
        try:
            # Si ya es MathExpertResponse, devolverlo tal cual
            if isinstance(respuesta, MathExpertResponse):
                return respuesta
            
            # Si es dict, convertir a MathExpertResponse
            if isinstance(respuesta, dict):
                return MathExpertResponse(
                    explanation=respuesta.get('explanation', f'Explicaci√≥n sobre: {consulta}'),
                    formulas=respuesta.get('formulas', []),
                    difficulty_level=respuesta.get('difficulty_level', 'b√°sico'),
                    related_concepts=respuesta.get('related_concepts', [])
                )
            
            # Si es string (JSON), parsearlo primero
            if isinstance(respuesta, str):
                try:
                    json_data = json.loads(respuesta)
                    return MathExpertResponse(
                        explanation=json_data.get('explanation', f'Explicaci√≥n sobre: {consulta}'),
                        formulas=json_data.get('formulas', []),
                        difficulty_level=json_data.get('difficulty_level', 'b√°sico'),
                        related_concepts=json_data.get('related_concepts', [])
                    )
                except json.JSONDecodeError:
                    pass
            
            # Fallback si no se puede convertir
            logger.warning(f"No se pudo convertir respuesta de tipo {type(respuesta)}, usando fallback")
            return MathExpertResponse(
                explanation=f"Respuesta sobre: {consulta}. {str(respuesta)[:200]}",
                formulas=[],
                difficulty_level='b√°sico',
                related_concepts=[]
            )
            
        except Exception as e:
            logger.error(f"Error convirtiendo respuesta: {e}")
            return MathExpertResponse(
                explanation=f"Error procesando consulta sobre: {consulta}",
                formulas=[],
                difficulty_level='b√°sico',
                related_concepts=[]
            )
    def _extraer_contexto_conversacional(self, estado: EstadoConversacion) -> str:
        """Extrae contexto relevante de la conversaci√≥n previa"""
        contexto_partes = []
        
        # Buscar respuestas previas de agentes
        for mensaje in estado.chat_history[-5:]:
            if mensaje.get("role") == "exam_creator":
                contexto_partes.append(f"EXAMEN CREADO PREVIAMENTE:\n{mensaje['content']}\n")
            elif mensaje.get("role") == "math_expert":
                contexto_partes.append(f"EXPLICACI√ìN PREVIA:\n{mensaje['content'][:300]}...\n")
        
        if not contexto_partes:
            return "No hay contexto conversacional previo."
        
        return "\n".join(contexto_partes)